# Запуск
```powershell
make run
```

# Отчёт по решению

## 1. Подход к решению задачи  
Я использовал модель **Llama** через `llama_cpp` для генерации однострочных выражений на Python, которые извлекают нужные данные из `pandas.DataFrame`.  
Пользователь задаёт вопрос, модель возвращает строку кода, которая затем исполняется, и результат интерпретируется снова через LLM.

## 2. Эффективность и точность  
Система показывает хорошую стабильность при адекватных пользовательских запросах.  
Однострочные ответы от модели в основном корректны и дают нужный результат.  
Иногда могут встречаться лишние символы или пробелы, которые приходится убирать.

## 3. Методы и технологии  
- Модель: `CodeLlama-13B-Instruct` через `llama_cpp`  
- Безопасное выполнение кода: `RestrictedPython`  
- Работа с данными: `pandas`  
- История диалога формируется вручную в стиле ChatML (`[INST]...[/INST]`)  

**Что сработало:**  
- Генерация корректных однострочных выражений  
- Гибкость диалогов  

**Что не сработало:**  
- Без хорошего контекста модель может ошибаться или давать неполный ответ

## 4. Критерии оценки качества  
- Код должен быть исполняемым  
- Результат должен быть логично связан с вопросом  
- Ответ должен быть **однострочной строкой** Python-кода, без комментариев  
- Заключение на основе результата должно быть связным и кратким
